{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Model Demo Full CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.activation.relu import ReluLayer\n",
    "from src.layers.pooling import MaxPoolLayer\n",
    "from src.activation.softmax import SoftmaxLayer\n",
    "from src.layers.dense import DenseLayer\n",
    "from src.layers.flatten import FlattenLayer\n",
    "from src.layers.convolutional import ConvLayer2D, SuperFastConvLayer2D\n",
    "from src.layers.dropout import DropoutLayer\n",
    "from src.model.sequential import SequentialModel\n",
    "from src.utils.core import convert_categorical2one_hot, convert_prob2categorical\n",
    "from src.utils.metrics import softmax_accuracy\n",
    "from src.optimizers.gradient_descent import GradientDescent\n",
    "from src.optimizers.rms_prop import RMSProp\n",
    "from src.optimizers.adam import Adam\n",
    "from src.utils.plots import lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./covid_19_data2/x.npy')\n",
    "x_train = x_train.reshape(len(x_train), 224,224,1)\n",
    "y_train = np.load('./covid_19_data2/y.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[:1000]\n",
    "y_train=y_train[:1000]\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train,\n",
    "                                                    y_train, \n",
    "                                                    test_size=0.3, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=1004)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    # input (N, 28, 28, 1) out (N, 28, 28, 32)\n",
    "    SuperFastConvLayer2D.initialize(filters=64, kernel_shape=(3, 3, 1), stride=1, padding=\"same\"),\n",
    "    # input (N, 28, 28, 32) out (N, 28, 28, 32)\n",
    "    ReluLayer(),\n",
    "    MaxPoolLayer(pool_size=(2, 2), stride=2),\n",
    "    DropoutLayer(keep_prob=0.75),\n",
    "    # input (N, 28, 28, 32) out (N, 28, 28, 32)\n",
    "    SuperFastConvLayer2D.initialize(filters=128, kernel_shape=(3, 3, 64), stride=1, padding=\"same\"),\n",
    "    # input (N, 28, 28, 32) out (N, 28, 28, 32)\n",
    "    ReluLayer(),\n",
    "    # input (N, 28, 28, 32) out (N, 14, 14, 32)\n",
    "    MaxPoolLayer(pool_size=(2, 2), stride=2),\n",
    "    DropoutLayer(keep_prob=0.75),\n",
    "    # input (N, 14, 14, 32) out (N, 14, 14, 32)\n",
    "    # input (N, 7, 7, 64) out (N, 7 * 7 * 64)\n",
    "    FlattenLayer(),\n",
    "    # input (N, 7 * 7 * 64) out (N, 256)\n",
    "    DenseLayer.initialize(units_prev=56*56*128, units_curr=3),\n",
    "    # input (N, 256) out (N, 256)\n",
    "    # input (N, 10) out (N, 10)\n",
    "    SoftmaxLayer()\n",
    "]\n",
    "\n",
    "optimizer = Adam(lr=0.003)\n",
    "\n",
    "model = SequentialModel(\n",
    "    layers=layers,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    x_train=X_train, \n",
    "    y_train=y_train, \n",
    "    x_test=X_test, \n",
    "    y_test=y_test, \n",
    "    epochs=5,\n",
    "    bs=4,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Predict and examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines(\n",
    "    y_1=np.array(model.history[\"train_acc\"]),\n",
    "    y_2=np.array(model.history[\"test_acc\"]),\n",
    "    label_1=\"train\",\n",
    "    label_2=\"test\",\n",
    "    title=\"ACCURACY\",\n",
    "    fig_size=(16,10),\n",
    "    path=\"../viz/cnn_acc.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines(\n",
    "    y_1=np.array(model.history[\"train_loss\"]),\n",
    "    y_2=np.array(model.history[\"test_loss\"]),\n",
    "    label_1=\"train\",\n",
    "    label_2=\"test\",\n",
    "    title=\"LOSS\",\n",
    "    fig_size=(16,10),\n",
    "    path=\"../viz/cnn_loss.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_valid)\n",
    "acc = softmax_accuracy(y_hat, y_valid)\n",
    "print(\"acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = convert_prob2categorical(y_hat)\n",
    "y_valid = convert_prob2categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(\n",
    "    confusion_matrix(y_valid, y_hat), \n",
    "    range(10), \n",
    "    range(10)\n",
    ")\n",
    "plt.figure(figsize = (16,16))\n",
    "sn.heatmap(df_cm, annot=True, cmap=\"YlGnBu\", linewidths=.5, cbar=False)\n",
    "plt.savefig(\"../viz/cm.png\", dpi=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
